{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gk1E6Ww-3is9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import streamlit as st\n",
        "from dotenv import load_dotenv\n",
        "import google.generativeai as gen_ai\n",
        "\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Configure Streamlit page settings\n",
        "st.set_page_config(\n",
        "    page_title=\"Chat with Gemini-Pro!\",\n",
        "    page_icon=\":brain:\",  # Favicon emoji\n",
        "    layout=\"centered\",  # Page layout option\n",
        ")\n",
        "\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# Set up Google Gemini-Pro AI model\n",
        "gen_ai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = gen_ai.GenerativeModel('gemini-pro')\n",
        "\n",
        "\n",
        "# Function to translate roles between Gemini-Pro and Streamlit terminology\n",
        "def translate_role_for_streamlit(user_role):\n",
        "    if user_role == \"model\":\n",
        "        return \"assistant\"\n",
        "    else:\n",
        "        return user_role\n",
        "\n",
        "\n",
        "# Initialize chat session in Streamlit if not already present\n",
        "if \"chat_session\" not in st.session_state:\n",
        "    st.session_state.chat_session = model.start_chat(history=[])\n",
        "\n",
        "\n",
        "# Display the chatbot's title on the page\n",
        "st.title(\"ðŸ¤– Gemini Pro - ChatBot\")\n",
        "\n",
        "# Display the chat history\n",
        "for message in st.session_state.chat_session.history:\n",
        "    with st.chat_message(translate_role_for_streamlit(message.role)):\n",
        "        st.markdown(message.parts[0].text)\n",
        "\n",
        "# Input field for user's message\n",
        "user_prompt = st.chat_input(\"Ask Gemini-Pro...\")\n",
        "if user_prompt:\n",
        "    # Add user's message to chat and display it\n",
        "    st.chat_message(\"user\").markdown(user_prompt)\n",
        "\n",
        "    # Send user's message to Gemini-Pro and get the response\n",
        "    gemini_response = st.session_state.chat_session.send_message(user_prompt)\n",
        "\n",
        "    # Display Gemini-Pro's response\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(gemini_response.text)"
      ]
    }
  ]
}